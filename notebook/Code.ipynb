{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONjewesqEe0WKsenpL5sRf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Μεταφόρτωση αρχείων από το τοπικό σύστημα.\n",
        "\n",
        "Με την βιβλιοθήκη <code>files</code> από το <code>google.colab</code> ανεβάζω τα απαραίτητα αρχεία για την υλοποίηση της άσκησης."
      ],
      "metadata": {
        "id": "nyQ_DLw3RYpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "1oUot66vO6Uu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c23cc570-fa48-4ed2-d4f4-59e53ed34361"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ceeb0745-3592-4b76-a9fa-3b7eb68bf824\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ceeb0745-3592-4b76-a9fa-3b7eb68bf824\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset-HAR-PUC-Rio.csv to dataset-HAR-PUC-Rio.csv\n",
            "User uploaded file \"dataset-HAR-PUC-Rio.csv\" with length 14283211 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "> **Γιατί κάνουμε data preprocessing**: Το data set μας πολύ πιθανών να αποτελείται απο features διαφορετικών range.Για παράδειγμα, το ένα feature μπορεί να είναι η ηλικία ενός ατόμου που κυμαίνεται στο διάστημα $[0,120]$, ενώ ένα άλλο feature μπορεί να αναφέρεται σε κάποιο χρηματικό ποσό που κυμαίνεται στο διάστημα $[0,100000]$.Αυτό έχει ως αποτέλεσμα το δεύτερο feature να επηρεάζει περισσότερο την έξοδο από το πρώτο.Επομένως προσθέτουμε ένα bias ως προς το δεύτερο χαρακτηριστικό.<br><br>\n",
        ">**Normalization**: Με αυτή την μέθοδο μεταφέρουμε το εύρος κάθε feature στο διάστημα $[0,1]$.Έτσι επιλύουμε το παραπάνω πρόβλημα.Αυτή η μέθοδος χρησιμοποιείται σε αλγόριθμους που δεν κάνουν υποθέσεις για την κατανομή των δεδομένων , όπως τα **neural networks**.Για αυτό τον λόγο θα χρησιμοποιηθεί αυτή η τεχνική για το πρόβλημά μας.<br><br>\n",
        ">**Standarization**: Αυτή η μέθοδος υποθέτει ότι τα δεδομένα ακολουθούν gaussian distribution μετασχηματίζοντας τα έτσι ώστε να έχουν μηδενική μέση τιμή και διασπορά ίση με 1.Χρησιμοποιείται λοιπόν σε αλγόριθμους που υποθέτουν ότι τα δεδομένα ακολουθούν gaussian distribution όπως το **linear regresion**.<br><br>\n",
        ">**Centralization**: Αυτή η μέθοδος μετασχηματίζει τα δεδομένα έτσι ώστε να έχουν μηδενική μέση τιμή. Παρόλα αυτά δεν λύνει το πρόβλημα που αναφέρθηκε παραπάνω."
      ],
      "metadata": {
        "id": "BwiepQ-8tT5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.offsets import YearBegin\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# read dataset\n",
        "dataset = pd.read_csv(\"dataset-HAR-PUC-Rio.csv\",delimiter=\";\", low_memory=False)\n",
        "\n",
        "# create dictionary that maps strings to numbers\n",
        "string_to_num = {'debora': 1, 'katia': 2, 'wallace': 3, 'jose_carlos': 4, 'Woman': 1, 'Man': 2 }\n",
        "\n",
        "# lambda function\n",
        "def map_strings_to_nums(col):\n",
        "    return col.apply(lambda x: string_to_num[x] if x in string_to_num else x)\n",
        "\n",
        "# apply lambda function to string columns\n",
        "dataset[['user', 'gender', 'class']] = dataset[['user', 'gender', 'class']].apply(map_strings_to_nums)\n",
        "\n",
        "# replace ',' with '.' so astype can work\n",
        "dataset['how_tall_in_meters'] = dataset['how_tall_in_meters'].str.replace(',','.')\n",
        "dataset['body_mass_index'] = dataset['body_mass_index'].str.replace(',','.')\n",
        "\n",
        "# split features and Output\n",
        "X = dataset.drop('class', axis=1)\n",
        "\n",
        "labels = dataset['class'].values.reshape(-1, 1)\n",
        "encoder = OneHotEncoder()\n",
        "Y = pd.DataFrame(encoder.fit_transform(labels).toarray())\n",
        "\n",
        "X = X.astype(float)\n",
        "Y = Y.astype(float)\n",
        "# Normalize features\n",
        "#scaler = MinMaxScaler()\n",
        "#dataset_normalized = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n"
      ],
      "metadata": {
        "id": "1ePjNVTMyIe5"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation\n",
        "\n",
        "> **Γιατί;**: Αυτή η μέθοδος χρησιμοποιείται για να εξασφαλίσουμε ότι το score του αλγορίθμου μας δεν εξαρτάται από τον τρόπο που επιλέγουμε τα <code>train_set</code> και <code>test_set</code>.<br><br>\n",
        "> **Πως**;: Χωρίζουμε το dataset σε Κ folds και χρησιμοποιούμε τα Κ-1 για <code>train_set</code> και το υπολοιπώμενο για <code>test_set</code> μέχρι και τα K folds να έχουν γίνει <code>test_set</code>.Στο πρόβλημα μας θα χρησιμοποιήσουμε 5-fold cross validation."
      ],
      "metadata": {
        "id": "EUzYdHbOHuh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=39)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, Y)):\n",
        "    print(f\"Fold {fold+1} Train Index: {train_idx}\")\n",
        "    print(f\"Fold {fold+1} Test Index: {test_idx}\")"
      ],
      "metadata": {
        "id": "HT9heYDzLx_u",
        "outputId": "01e53136-c48c-4e05-e1b0-f9e60ef1a46c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Train Index: [     1      2      3 ... 165628 165630 165631]\n",
            "Fold 1 Test Index: [     0      7     11 ... 165616 165626 165629]\n",
            "Fold 2 Train Index: [     0      1      3 ... 165629 165630 165631]\n",
            "Fold 2 Test Index: [     2     12     20 ... 165608 165619 165628]\n",
            "Fold 3 Train Index: [     0      1      2 ... 165628 165629 165630]\n",
            "Fold 3 Test Index: [     6     10     15 ... 165617 165627 165631]\n",
            "Fold 4 Train Index: [     0      1      2 ... 165629 165630 165631]\n",
            "Fold 4 Test Index: [     4     16     18 ... 165622 165623 165624]\n",
            "Fold 5 Train Index: [     0      2      4 ... 165628 165629 165631]\n",
            "Fold 5 Test Index: [     1      3      5 ... 165620 165625 165630]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Επιλογή Αρχιτεκτονικής"
      ],
      "metadata": {
        "id": "8kwWApa3Nd2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "metrics = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(dataset):\n",
        "    #number of input features\n",
        "    input_dim = 18\n",
        "    #number of nodes in hidden layer\n",
        "    hidden_dim = 64\n",
        "    # create a sequential model\n",
        "    model = Sequential()\n",
        "    # add a hidden layer with hidden_dim neurons and ReLU activation function\n",
        "    model.add(Dense(hidden_dim, input_dim=input_dim, activation='relu'))\n",
        "    # add an output layer with 5 neurons and softmax activation function\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    #compile the model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "    metrics.append(model.evaluate(X_test, y_test))\n",
        "\n",
        "avg_metrics = np.mean(metrics, axis=0)\n",
        "print(f'Average loss: {avg_metrics[0]}, Average accuracy: {avg_metrics[1]}')\n"
      ],
      "metadata": {
        "id": "wtvavqqVNifr",
        "outputId": "dbf1af49-e03b-4945-ff77-6dcc4105699d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4141/4141 [==============================] - 11s 2ms/step - loss: 1.0765 - accuracy: 0.8563 - val_loss: 0.3969 - val_accuracy: 0.9049\n",
            "Epoch 2/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.3271 - accuracy: 0.9203 - val_loss: 0.3581 - val_accuracy: 0.9321\n",
            "Epoch 3/10\n",
            "4141/4141 [==============================] - 9s 2ms/step - loss: 0.2595 - accuracy: 0.9371 - val_loss: 0.2058 - val_accuracy: 0.9477\n",
            "Epoch 4/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.2201 - accuracy: 0.9456 - val_loss: 0.1598 - val_accuracy: 0.9629\n",
            "Epoch 5/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.1768 - accuracy: 0.9541 - val_loss: 0.1851 - val_accuracy: 0.9627\n",
            "Epoch 6/10\n",
            "4141/4141 [==============================] - 11s 3ms/step - loss: 0.1595 - accuracy: 0.9591 - val_loss: 0.1652 - val_accuracy: 0.9532\n",
            "Epoch 7/10\n",
            "4141/4141 [==============================] - 15s 4ms/step - loss: 0.1419 - accuracy: 0.9626 - val_loss: 0.1219 - val_accuracy: 0.9658\n",
            "Epoch 8/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.1297 - accuracy: 0.9649 - val_loss: 0.1439 - val_accuracy: 0.9597\n",
            "Epoch 9/10\n",
            "4141/4141 [==============================] - 12s 3ms/step - loss: 0.1162 - accuracy: 0.9676 - val_loss: 0.1054 - val_accuracy: 0.9696\n",
            "Epoch 10/10\n",
            "4141/4141 [==============================] - 11s 3ms/step - loss: 0.1070 - accuracy: 0.9700 - val_loss: 0.0930 - val_accuracy: 0.9760\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 0.0930 - accuracy: 0.9760\n",
            "Epoch 1/10\n",
            "4141/4141 [==============================] - 11s 2ms/step - loss: 0.8015 - accuracy: 0.8641 - val_loss: 0.2700 - val_accuracy: 0.9290\n",
            "Epoch 2/10\n",
            "4141/4141 [==============================] - 9s 2ms/step - loss: 0.3043 - accuracy: 0.9277 - val_loss: 0.2179 - val_accuracy: 0.9469\n",
            "Epoch 3/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.2249 - accuracy: 0.9462 - val_loss: 0.1358 - val_accuracy: 0.9627\n",
            "Epoch 4/10\n",
            "4141/4141 [==============================] - 11s 3ms/step - loss: 0.1801 - accuracy: 0.9545 - val_loss: 0.1394 - val_accuracy: 0.9628\n",
            "Epoch 5/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.1559 - accuracy: 0.9604 - val_loss: 0.1471 - val_accuracy: 0.9630\n",
            "Epoch 6/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.1351 - accuracy: 0.9646 - val_loss: 0.1121 - val_accuracy: 0.9704\n",
            "Epoch 7/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.1179 - accuracy: 0.9682 - val_loss: 0.1022 - val_accuracy: 0.9722\n",
            "Epoch 8/10\n",
            "4141/4141 [==============================] - 11s 3ms/step - loss: 0.1080 - accuracy: 0.9711 - val_loss: 0.1001 - val_accuracy: 0.9745\n",
            "Epoch 9/10\n",
            "4141/4141 [==============================] - 11s 3ms/step - loss: 0.0973 - accuracy: 0.9732 - val_loss: 0.0838 - val_accuracy: 0.9781\n",
            "Epoch 10/10\n",
            "4141/4141 [==============================] - 10s 2ms/step - loss: 0.0931 - accuracy: 0.9737 - val_loss: 0.1103 - val_accuracy: 0.9667\n"
          ]
        }
      ]
    }
  ]
}